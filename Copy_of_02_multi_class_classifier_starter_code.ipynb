{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UD-1_xY-h2u"
      },
      "source": [
        "# Multi-class Classifier\n",
        "\n",
        "In this lab, you will look at how to build a model to distinguish between more than two classes. The code will be similar to the ones you've been using before with a few key changes in the model and in the training parameters. Let's dive in!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKp8LMo7v5ww"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxeHE_RLv5ww"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "\n",
        "# Plotting and dealing with images\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "\n",
        "# Interactive widgets\n",
        "from ipywidgets import widgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvwVR5lHA8q_"
      },
      "source": [
        "## Inspect the Dataset\n",
        "\n",
        "You will be using the [Rock-Paper-Scissors dataset](https://www.tensorflow.org/datasets/catalog/rock_paper_scissors), a gallery of hands images in Rock, Paper, and Scissors poses.\n",
        "\n",
        "As usual, you will assign the directory names into variables and look at the filenames as a sanity check."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K_Vo8otC-QQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrxdR83ANgjS"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = '/tmp/rps-test-set'\n",
        "\n",
        "rock_dir = os.path.join(BASE_DIR, 'rock')\n",
        "paper_dir = os.path.join(BASE_DIR, 'paper')\n",
        "scissors_dir = os.path.join(BASE_DIR, 'scissors')\n",
        "\n",
        "print(f'total training rock images: {len(os.listdir(\"/tmp/rps-test-set/paper\"))}')\n",
        "print(f'total training paper images: {len(os.listdir(\"/tmp/rps-test-set/rock\"))}')\n",
        "print(f'total training scissors images: {len(os.listdir(\"/tmp/rps-test-set/scissors\"))}')\n",
        "\n",
        "rock_files = os.listdir(rock_dir)\n",
        "paper_files = os.listdir(paper_dir)\n",
        "scissors_files = os.listdir(scissors_dir)\n",
        "\n",
        "print()\n",
        "print(f\"5 files in the rock subdir: {rock_files[:5]}\")\n",
        "print(f\"5 files in the paper subdir: {paper_files[:5]}\")\n",
        "print(f\"5 files in the scissors subdir: {scissors_files[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t_CNSs6B-8y"
      },
      "source": [
        "You can also inspect some of the images to see the variety in your model inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jp9dLel9N9DS"
      },
      "outputs": [],
      "source": [
        "next_rock = [os.path.join(rock_dir, fname)\n",
        "             for fname in random.sample(rock_files, k=2)]\n",
        "next_paper = [os.path.join(paper_dir, fname)\n",
        "              for fname in random.sample(paper_files, k=2)]\n",
        "next_scissors = [os.path.join(scissors_dir, fname)\n",
        "                 for fname in random.sample(scissors_files, k=2)]\n",
        "\n",
        "for i, img_path in enumerate(next_rock+next_paper+next_scissors):\n",
        "    img = mpimg.imread(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('Off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ps7kIRaFRIC"
      },
      "source": [
        "## Preprocess the Image Data\n",
        "\n",
        "You will prepare the training and validation datasets as before. The label mode will be `categorical` because you will predict more than two classes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use https://keras.io/api/data_loading/image/ to read the data\n",
        "from keras.utils import image_dataset_from_directory\n",
        "\n",
        "train, val = image_dataset_from_directory('/tmp/cats_and_dogs_filtered/train' ,\n",
        "                             label_mode ='binary',\n",
        "                             image_size = (155, 155),\n",
        "                             class_names = ['cats', 'dogs'],\n",
        "                             validation_split = 0.2,\n",
        "                             subset = 'both',\n",
        "                             seed = 123)\n",
        "\n",
        "\n",
        "test = image_dataset_from_directory('/tmp/cats_and_dogs_filtered/validation' ,\n",
        "                             label_mode ='binary',\n",
        "                             image_size = (155, 155),\n",
        "                             class_names = ['cats', 'dogs'],\n",
        "\n",
        "                             seed = 123)"
      ],
      "metadata": {
        "id": "vZxGYtckB0IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Au_DSdZ5pxRb"
      },
      "outputs": [],
      "source": [
        "from keras.utils import image_dataset_from_directory\n",
        "train , val = image_dataset_from_directory('/tmp/rps-test-set',\n",
        "                                           label_mode ='categorical',\n",
        "                                           image_size = (150, 150),\n",
        "                                           class_names = ['rock', 'paper', 'scissors'],\n",
        "                                           validation_split = 0.2,\n",
        "                                           subset = 'both',\n",
        "                                           seed = 123)\n",
        "test = image_dataset_from_directory('/tmp/rps-test-set',\n",
        "                                           label_mode ='categorical',\n",
        "                                           image_size = (150, 150),\n",
        "                                           class_names = ['rock', 'paper', 'scissors'],\n",
        "                                           seed = 123)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import models, datasets\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "fseFGFz2CzJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdTv_jIuygwu"
      },
      "source": [
        "## Prepare the Model for Training\n",
        "\n",
        "You will use data augmentation to generate other poses that the model needs to learn."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "MznynASrwYUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.0001),\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "Wu0deuk4Dq1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train,\n",
        "          epochs=10,\n",
        "          validation_data=val)"
      ],
      "metadata": {
        "id": "BJPCrS8xDvDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test)"
      ],
      "metadata": {
        "id": "2FdwIY8kFEGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(history.history)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "Om8aZX8KFG3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['acc'], label='accuracy')\n",
        "plt.plot(history.history['val_acc'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "kebEO_w8Ga8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufa0YF5oCpYw"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "You will then build your CNN. You will use 4 convolution layers with 64-64-128-128 filters then append a `Dropout` layer to avoid overfitting and some `Dense` layers for the classification. The output layer would be a 3-neuron `Dense` layer activated by [Softmax](https://www.tensorflow.org/api_docs/python/tf/nn/softmax). You've seen this in Course 1 when you were training with Fashion MNIST. It scales your output to a set of probabilities that add up to 1. The order of this 3-neuron output would be paper-rock-scissors (e.g. a `[0.8 0.2 0.0]` output means the model is predicting 80% probability for paper and 20% probability for rock.\n",
        "\n",
        "You can examine the architecture with `model.summary()` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrJEfhfEqlcJ"
      },
      "outputs": [],
      "source": [
        "from keras.applications.xception import Xception\n",
        "\n",
        "base_model = Xception(\n",
        "    weights='imagenet',\n",
        "    include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK-fS5koqcDX"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zTD9SgDz-cC"
      },
      "source": [
        "You will compile the model using a [`categorical_crossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) loss function to quantify the error across all 3 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY4G-rFVrCD2"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  keras.models import Sequential\n",
        "from  keras import layers\n",
        "import tensorflow as tr\n",
        "model_1= Sequential()\n",
        "model_1.add(base_model)\n",
        "model_1.add(layers.Flatten())\n",
        "model_1.add(layers.Dropout(0.5))\n",
        "model_1.add(layers.Dense(3, activation='softmax'))\n",
        "model_1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "history1=model_1.fit(\n",
        "    train,\n",
        "    epochs=10,\n",
        "    validation_data=val,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "VGb0yzUGG__t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(test)"
      ],
      "metadata": {
        "id": "xleSxAqdG_4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(val)"
      ],
      "metadata": {
        "id": "zSgEndwsMQiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history1.history['accuracy'], label='accuracy')\n",
        "plt.plot(history1.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WhWnXBrLMcq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Orf1QQlGGyOe"
      },
      "source": [
        "## Train the model and evaluate the results\n",
        "\n",
        "You will train for 25 epochs and evaludate the results afterwards. Observe how both the training and validation accuracy are trending upwards. This is a good indication that the model is not overfitting to the training set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mHX5L7HFXQ7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeTRVCr6aosw"
      },
      "outputs": [],
      "source": [
        "def plot_loss_acc(history):\n",
        "  '''Plots the training and validation loss and accuracy from a history object'''\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(acc))\n",
        "\n",
        "  fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
        "  ax[0].plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "  ax[0].plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "  ax[0].set_title('Training and validation accuracy')\n",
        "  ax[0].set_xlabel('epochs')\n",
        "  ax[0].set_ylabel('accuracy')\n",
        "  ax[0].legend()\n",
        "\n",
        "  ax[1].plot(epochs, loss, 'bo', label='Training Loss')\n",
        "  ax[1].plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "  ax[1].set_title('Training and validation loss')\n",
        "  ax[1].set_xlabel('epochs')\n",
        "  ax[1].set_ylabel('loss')\n",
        "  ax[1].legend()\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "plot_loss_acc(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3ps8Q1tpYMG"
      },
      "source": [
        "# Model Prediction\n",
        "\n",
        "You can feed in a picture and have the model classify it as rock, paper, or scissors. You can upload your own images or use the ones available [here](https://storage.googleapis.com/tensorflow-1-public/course2/week4/rps-validation.zip)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZABJp7T3VLCU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHRufhQYJJLU"
      },
      "source": [
        "## Wrap Up\n",
        "\n",
        "That concludes this short exercise on the multi-class classifiers. You saw that with just a few changes, you were able to convert your binary classifiers to predict more classes. You used the same techniques for data and model preparation and were able to get relatively good results in just 25 epochs. For practice, you can search for other datasets (e.g. [here](https://archive.ics.uci.edu/datasets)) with more classes and revise the model to accomodate it. Try to experiment with different layers and data augmentation techniques to improve your metrics."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}